{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from dataloader import DataLoad\n",
    "import argparse\n",
    "from model import Model\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "import time\n",
    "from sample import *\n",
    "import hyperopt as hp\n",
    "from hyperopt import fmin, tpe, hp, partial\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TestArgs(object):\n",
    "    def __init__(self):          \n",
    "        self.hidden_layers = 2\n",
    "        self.seq_len = 12\n",
    "        self.dist = 5.0\n",
    "        self.hidden_size = 64\n",
    "        self.drop_out = 0.7\n",
    "        self.learning_rate = 0.005\n",
    "        self.epoch = 1\n",
    "        self.batch_size = 64\n",
    "        self.model_type = 'BLSTM_MDN_model'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A sequence didn't match the criteria\n",
      "A sequence didn't match the criteria\n",
      "A sequence didn't match the criteria\n",
      "A sequence didn't match the criteria\n",
      "A sequence didn't match the criteria\n",
      "A sequence didn't match the criteria\n",
      "A sequence didn't match the criteria\n",
      "A sequence didn't match the criteria\n",
      "A sequence didn't match the criteria\n",
      "A sequence didn't match the criteria\n",
      "A sequence didn't match the criteria\n",
      "After preprocess, we lost 218 sequences in sum\n",
      "we have 20434 samples in sum, including 16347 traing samples, and 4087 test samples\n",
      "type of X_train is <type 'numpy.ndarray'>, shape of X_train is (num_sample, seq_len, crd): (16347, 12, 4)\n",
      "type of y_train is <type 'numpy.ndarray'>, shape of y_train is (num_sample, ): (16347,)\n",
      "--------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#=======step 1: get args for model=======\n",
    "args = TestArgs()\n",
    "#=======step 2: preprocess data==========\n",
    "direc = './data/'  # directory of data file\n",
    "csv_file = 'seq_all.csv'\n",
    "dl = DataLoad(direc, csv_file)\n",
    "dl.munge_data(height=11.0, seq_len=args.seq_len, dist=args.dist)\n",
    "basket_center = np.array([5.25, 25.0, 10.0])\n",
    "dl.center_data(center_cent=basket_center)\n",
    "sum_samples, num_train, num_test = dl.test_valid_data_split(ratio=0.8)\n",
    "print \"--------------------------------------------------------------------\"\n",
    "X_train = dl.data['X_train']\n",
    "y_train = dl.data['y_train']\n",
    "X_test = dl.data['X_test']\n",
    "y_test = dl.data['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are using 3 mixtures\n"
     ]
    }
   ],
   "source": [
    "#=======step 3: construct model==========\n",
    "tf.reset_default_graph()\n",
    "model = Model(args)\n",
    "if args.model_type == 'LSTM_model':\n",
    "  model.LSTM_model()\n",
    "elif args.model_type == 'bidir_LSTM_model':\n",
    "  model.bidir_LSTM_model()\n",
    "elif args.model_type == 'CNN_model':\n",
    "  model.CNN_model()\n",
    "elif args.model_type == 'Conv_LSTM_model':\n",
    "  model.Conv_LSTM_model()\n",
    "elif args.model_type == 'LSTM_MDN_model':\n",
    "  model.MDN_model('LSTM')\n",
    "elif args.model_type == 'BLSTM_MDN_model':\n",
    "  model.MDN_model('BLSTM')\n",
    "else:\n",
    "  print \"please choose correct model type\"\n",
    "model.Evaluating()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at 0 epoch, the training cost is -0.530063033104, the training accuracy is 0.703125\n",
      "at 0 epoch, the test cost is -0.63890504837, the test accuracy is 0.5625\n",
      "at 0 epoch, the test_AUC is 0.553887747478\n",
      "------------------------------------------------------\n",
      "========================================================\n",
      "Finally, at distance 5.0, the best test AUC is 0.553887747478 at 0 epoch,\n",
      "Finally, the model has 35994 parameters\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#=======step 4: start training===========\n",
    "start_time = time.time()\n",
    "train_cost_list = []\n",
    "test_cost_list = []\n",
    "test_AUC_list = []\n",
    "with tf.Session() as sess:\n",
    "  sess.run(tf.global_variables_initializer())\n",
    "  for i in range(args.epoch):\n",
    "    for batch_num in range(num_train / args.batch_size):\n",
    "      perm_ind = np.random.choice(\n",
    "          num_train, args.batch_size, replace=False)\n",
    "      feed_dict = {model.X: X_train[perm_ind], model.y: y_train[\n",
    "          perm_ind], model.drop_out: args.drop_out}\n",
    "      fetch = [model.train_op, model.accuracy,\n",
    "               model.cost]\n",
    "      _, train_acc, train_cost = sess.run(\n",
    "          fetch, feed_dict=feed_dict)\n",
    "    train_cost_list.append(train_cost)\n",
    "\n",
    "    #=======step 5: start testing============\n",
    "    test_AUC_batch_list = []\n",
    "    test_cost_batch_list = []\n",
    "    # shuffle test data\n",
    "    X_test, y_test = shuffle(\n",
    "        X_test, y_test, random_state=i * 42)\n",
    "    for start, end in zip(range(0, num_test, args.batch_size),\n",
    "                          range(args.batch_size, num_test + 1, args.batch_size)):\n",
    "\n",
    "      feed_dict = {model.X: X_test[start:end], model.y: y_test[\n",
    "          start:end], model.drop_out: 1.0}\n",
    "      fetch = [model.accuracy, model.cost, model.y_pred, model.numel]\n",
    "      test_acc, test_cost_batch, y_pred, numel = sess.run(\n",
    "          fetch, feed_dict=feed_dict)\n",
    "      test_AUC_batch = sklearn.metrics.roc_auc_score(\n",
    "          y_test[start: end], y_pred[:, 1])\n",
    "      test_AUC_batch_list.append(test_AUC_batch)\n",
    "      test_cost_batch_list.append(test_cost_batch)\n",
    "    test_AUC = np.mean(test_AUC_batch_list)\n",
    "    test_cost = np.mean(test_cost_batch_list)\n",
    "\n",
    "    test_AUC_list.append(test_AUC)\n",
    "    test_cost_list.append(test_cost)\n",
    "\n",
    "    print \"at {} epoch, the training cost is {}, the training accuracy is {}\".format(i, train_cost, train_acc)\n",
    "    print \"at {} epoch, the test cost is {}, the test accuracy is {}\".format(i, test_cost, test_acc)\n",
    "    print \"at {} epoch, the test_AUC is {}\".format(i, test_AUC)\n",
    "    print \"------------------------------------------------------\"\n",
    "\n",
    "\n",
    "\n",
    "    #----early stop---------\n",
    "    # if test_AUC start to decrease, then stop caculating\n",
    "    if i > 10:\n",
    "      mean_test_AUC = np.mean(test_AUC_list[-10:])\n",
    "\n",
    "      if test_AUC < mean_test_AUC * 0.8:\n",
    "        break\n",
    "\n",
    "  best_AUC = max(test_AUC_list)\n",
    "  best_AUC_ind = test_AUC_list.index(best_AUC)\n",
    "  end_time = time.time()\n",
    "  spend_time = end_time - start_time\n",
    "\n",
    "  print \"========================================================\"\n",
    "  print \"Finally, at distance {}, the best test AUC is {} at {} epoch,\".format(args.dist, best_AUC, best_AUC_ind)\n",
    "  print \"Finally, the model has {} parameters\\n\\n\".format(numel)\n",
    "  # wirte result in local\n",
    "  with open(args.model_type + '.txt', 'a') as f:\n",
    "    f.write(\"At distance {}, the best test AUC is {} at {} epoch, the model has {} parameters, lr_rate is {}, dropout is {}, batchsize is {}, spend time is {}, \\n\\n\"\n",
    "            .format(args.dist, best_AUC, best_AUC_ind, numel, args.learning_rate, args.drop_out, args.batch_size, spend_time))\n",
    "\n",
    "    \n",
    "  #=======step 6: draw figures============ \n",
    "  generate_trajectory = True\n",
    "  if generate_trajectory:\n",
    "    if args.model_type == 'LSTM_MDN_model' or args.model_type == 'BLSTM_MDN_model':\n",
    "      perm_ind = np.random.choice(num_test, args.batch_size, replace=False)\n",
    "      val_dict = {model.X: X_test[perm_ind], model.y: y_test[\n",
    "          perm_ind], model.drop_out: 1.0}\n",
    "      batch = X_test[perm_ind]\n",
    "\n",
    "      plot_traj_MDN_mult(model, sess, val_dict, batch)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(train_cost_list, 'r', label='train_cost')\n",
    "    plt.plot(test_cost_list, '--r', label='test_cost')\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "    plt.plot(test_AUC_list, label='test_AUC')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempted to use a closed Session.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-083b6695ea9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperm_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mplot_traj_MDN_mult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/zhaoyu106/Desktop/basketball_trajectory_prediction/sample.pyc\u001b[0m in \u001b[0;36mplot_traj_MDN_mult\u001b[0;34m(model, sess, val_dict, batch, sl_plot, ind)\u001b[0m\n\u001b[1;32m     17\u001b[0m   - ind: some index into the batch. if -1, we'll pick a random one\"\"\"\n\u001b[1;32m     18\u001b[0m   result = sess.run([model.mu1, model.mu2, model.mu3, model.s1,\n\u001b[0;32m---> 19\u001b[0;31m                      model.s2, model.s3, model.rho, model.theta], feed_dict=val_dict)\n\u001b[0m\u001b[1;32m     20\u001b[0m   \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m   \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/zhaoyu106/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/zhaoyu106/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    901\u001b[0m     \u001b[0;31m# Check session.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Attempted to use a closed Session.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m       raise RuntimeError('The Session graph is empty.  Add operations to the '\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempted to use a closed Session."
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
